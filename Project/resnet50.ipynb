{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"resnet50.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"m-WuXHXZJYih","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import numpy as np\n","import tensorflow as tf\n","\n","tf.logging.set_verbosity(tf.logging.INFO)\n","\n","_BATCH_NORM_DECAY = 0.997\n","_BATCH_NORM_EPSILON = 1e-5\n","\n","def batch_norm(inputs, training):\n","  return tf.layers.batch_normalization(\n","      inputs=inputs, axis=3,\n","      momentum=_BATCH_NORM_DECAY, epsilon=_BATCH_NORM_EPSILON, center=True,\n","      scale=True, training=training, fused=True)\n","\n","def fixed_padding(inputs, kernel_size):\n","  \"\"\"Pads the input along the spatial dimensions independently of input size.\"\"\"\n","  pad_total = kernel_size - 1\n","  pad_beg = pad_total // 2\n","  pad_end = pad_total - pad_beg\n","\n","  padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg, pad_end],\n","                                    [pad_beg, pad_end], [0, 0]])\n","  return padded_inputs\n","\n","\n","def conv2d_fixed_padding(inputs, filters, kernel_size, strides):\n","  \"\"\"Strided 2-D convolution with explicit padding.\"\"\"\n","  if strides > 1:\n","    inputs = fixed_padding(inputs, kernel_size)\n","\n","  return tf.layers.conv2d(\n","      inputs=inputs, filters=filters, kernel_size=kernel_size, strides=strides,\n","      padding=('SAME' if strides == 1 else 'VALID'), use_bias=False,\n","      kernel_initializer=tf.variance_scaling_initializer())\n","\n","def resnetUnit(input, filters, kernel_size, strides, bottleneck, training):\n","  \"\"\"A resnet50 unit with two branches.\"\"\"\n","  shortcut = input\n","  if bottleneck:\n","    shortcut = conv2d_fixed_padding(\n","      inputs=shortcut, filters=filters[3], strides=strides[3], kernel_size=kernel_size[3])\n","    shortcut = batch_norm(shortcut, training)\n","  \n","  input = conv2d_fixed_padding(\n","      inputs=input, filters=filters[0], strides=strides[0], kernel_size=kernel_size[0])\n","  input = batch_norm(input, training)\n","  input = conv2d_fixed_padding(\n","      inputs=input, filters=filters[1], strides=strides[1], kernel_size=kernel_size[1])\n","  input = batch_norm(input, training)\n","  input = conv2d_fixed_padding(\n","      inputs=input, filters=filters[2], strides=strides[2], kernel_size=kernel_size[2])\n","  input = batch_norm(input, training)\n","  \n","  return tf.nn.relu(input + shortcut)\n","  \n","\n","def resnet50(features, mode):\n","  training = (mode == \"TRAIN\")\n","\n","  # Input Layer\n","  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n","  #input_layer = tf.reshape(features[\"x\"], [-1, 224, 224, 3])\n","  input_layer = tf.reshape(features, [-1, 28, 28, 1])\n","\n","\n","  # Convolutional Layer #1\n","  conv1 = conv2d_fixed_padding(\n","      inputs=input_layer, filters=64, strides=2, kernel_size=7)\n","  conv1_norm = batch_norm(conv1, training)\n","  conv1_relu = tf.nn.relu(conv1_norm)\n","  pool1 = tf.layers.max_pooling2d(\n","    inputs=conv1_relu, pool_size=3, strides=2, padding='SAME',\n","    data_format='channels_last')\n","  \n","  kernel_size = [1, 3, 1, 1]\n","  filters_2 = [64, 64, 256, 256]\n","  strides_2 = [1, 1, 1, 1]\n","  \n","  #res2a\n","  res2a_relu = resnetUnit(pool1, filters_2, kernel_size, strides_2,\n","                          bottleneck = True, training = training)\n","  res2b_relu = resnetUnit(res2a_relu, filters_2, kernel_size, strides_2,\n","                          bottleneck = False, training = training)\n","  res2c_relu = resnetUnit(res2b_relu, filters_2, kernel_size, strides_2,\n","                          bottleneck = False, training = training)\n","  \n","  #res3a\n","  filters_3 = [128, 128, 512, 512]\n","  strides_3 = [2, 1, 1, 2]\n","  res3a_relu = resnetUnit(res2c_relu, filters_3, kernel_size, strides_3,\n","                          bottleneck = True, training = training)\n","  res3b_relu = resnetUnit(res3a_relu, filters_3, kernel_size, strides_2,\n","                          bottleneck = False, training = training)\n","  res3c_relu = resnetUnit(res3b_relu, filters_3, kernel_size, strides_2,\n","                          bottleneck = False, training = training)\n","  res3d_relu = resnetUnit(res3c_relu, filters_3, kernel_size, strides_2,\n","                          bottleneck = False, training = training)\n","  \n","  #res4a\n","  filters_4 = [256, 256, 1024, 1024]\n","  res4a_relu = resnetUnit(res3d_relu, filters_4, kernel_size, strides_3,\n","                          bottleneck = True, training = training)\n","  res4b_relu = resnetUnit(res4a_relu, filters_4, kernel_size, strides_2,\n","                          bottleneck = False, training = training)  \n","  res4c_relu = resnetUnit(res4b_relu, filters_4, kernel_size, strides_2,\n","                          bottleneck = False, training = training)  \n","  res4d_relu = resnetUnit(res4c_relu, filters_4, kernel_size, strides_2,\n","                          bottleneck = False, training = training)  \n","  res4e_relu = resnetUnit(res4d_relu, filters_4, kernel_size, strides_2,\n","                          bottleneck = False, training = training)  \n","  res4f_relu = resnetUnit(res4e_relu, filters_4, kernel_size, strides_2,\n","                          bottleneck = False, training = training) \n","  \n","  #res5a\n","  filters_5 = [512, 512, 2048, 2048]\n","  res5a_relu = resnetUnit(res4f_relu, filters_5, kernel_size, strides_3,\n","                          bottleneck = True, training = training)\n","  res5b_relu = resnetUnit(res5a_relu, filters_5, kernel_size, strides_2,\n","                          bottleneck = False, training = training) \n","  res5c_relu = resnetUnit(res5b_relu, filters_5, kernel_size, strides_2,\n","                          bottleneck = False, training = training) \n","\n","  # ResNet does an Average Pooling layer over pool_size.\n","  # Do a reduce_mean because it performs better than AveragePooling2D.\n","  axes = [1, 2]\n","  inputs = tf.reduce_mean(res5c_relu, axes, keepdims=True)\n","  inputs = tf.reshape(inputs, [-1, 1*1*2048])\n","  \n","  dense = tf.layers.dense(inputs=inputs, units=1000, activation=tf.nn.relu)\n","  dropout = tf.layers.dropout(inputs=dense, rate=0.5, training=training)\n","\n","  logits = tf.layers.dense(inputs=dropout, units=10)\n","  \n","  return tf.nn.softmax(logits)\n","\n","def loss(labels, logits):\n","  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n","  return loss\n","\n","\n","\n","def _generate_image_and_label_batch(image, label, min_queue_examples, batch_size):\n","  \"\"\"Construct a queued batch of images and labels.\n","  Args:\n","    image: 3-D Tensor of [height, width, 3] of type.float32.\n","    label: 1-D Tensor of type.int32\n","    min_queue_examples: int32, minimum number of samples to retain\n","      in the queue that provides of batches of examples.\n","    batch_size: Number of images per batch.\n","    shuffle: boolean indicating whether to use a shuffling queue.\n","  Returns:\n","    images: Images. 4D tensor of [batch_size, height, width, 3] size.\n","    labels: Labels. 1D tensor of [batch_size] size.\n","  \"\"\"\n","  # Create a queue that shuffles the examples, and then\n","  # read 'batch_size' images + labels from the example queue.\n","  num_preprocess_threads = 16\n","  images, label_batch = tf.train.shuffle_batch(\n","      [image, label],\n","      batch_size=batch_size,\n","      num_threads=num_preprocess_threads,\n","      capacity=min_queue_examples + 3 * batch_size,\n","      min_after_dequeue=min_queue_examples)\n","\n","  return images, tf.reshape(label_batch, [batch_size])\n","\n","\n","def main(unused_argv):\n","  # Load training and eval data\n","  mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n","  train_data = mnist.train.images  # Returns np.array\n","  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n","  eval_data = mnist.test.images  # Returns np.array\n","  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n","\n","  y = tf.placeholder(tf.int32, [None])\n","  x = tf.placeholder(tf.float32, [100, 784])\n","  y_ = resnet50(features = x, mode= \"TRAIN\")\n","  crossEntropy = loss(y, y_)\n","  train_step = tf.train.GradientDescentOptimizer(0.005).minimize(crossEntropy)\n","\n","  sess = tf.InteractiveSession()\n","  tf.global_variables_initializer().run()\n","  # Train\n","  for i in range(10):\n","    #batch_xs, batch_ys = mnist.train.next_batch(100)\n","    sess.run(train_step, feed_dict={x: train_data, y_: train_labels})\n","\n","  # Test trained model\n","  correct_prediction = tf.equal(tf.argmax(y, 1), y_)\n","  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","  print(sess.run(\n","      accuracy, feed_dict={\n","          x: mnist.test.images,\n","          y_: mnist.test.labels\n","      }))\n","  \n","  \n","if __name__ == \"__main__\":\n","  tf.app.run()\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NIRkGfOah5Ei","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":608},"outputId":"92755a85-5b0a-4db7-ca84-d4f04f62f4bb","executionInfo":{"status":"error","timestamp":1528077996762,"user_tz":420,"elapsed":24377,"user":{"displayName":"Deren Lei","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"105220816443262868036"}}},"cell_type":"code","source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import numpy as np\n","import tensorflow as tf\n","\n","tf.logging.set_verbosity(tf.logging.INFO)\n","\n","_BATCH_NORM_DECAY = 0.997\n","_BATCH_NORM_EPSILON = 1e-5\n","\n","def batch_norm(inputs, training):\n","  return tf.layers.batch_normalization(\n","      inputs=inputs, axis=3,\n","      momentum=_BATCH_NORM_DECAY, epsilon=_BATCH_NORM_EPSILON, center=True,\n","      scale=True, training=training, fused=True)\n","\n","def fixed_padding(inputs, kernel_size):\n","  \"\"\"Pads the input along the spatial dimensions independently of input size.\"\"\"\n","  pad_total = kernel_size - 1\n","  pad_beg = pad_total // 2\n","  pad_end = pad_total - pad_beg\n","\n","  padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg, pad_end],\n","                                    [pad_beg, pad_end], [0, 0]])\n","  return padded_inputs\n","\n","\n","def conv2d_fixed_padding(inputs, filters, kernel_size, strides):\n","  \"\"\"Strided 2-D convolution with explicit padding.\"\"\"\n","  if strides > 1:\n","    inputs = fixed_padding(inputs, kernel_size)\n","\n","  return tf.layers.conv2d(\n","      inputs=inputs, filters=filters, kernel_size=kernel_size, strides=strides,\n","      padding=('SAME' if strides == 1 else 'VALID'), use_bias=False,\n","      kernel_initializer=tf.variance_scaling_initializer())\n","\n","def resnetUnit(input, filters, kernel_size, strides, bottleneck, training):\n","  \"\"\"A resnet50 unit with two branches.\"\"\"\n","  shortcut = input\n","  if bottleneck:\n","    shortcut = conv2d_fixed_padding(\n","      inputs=shortcut, filters=filters[3], strides=strides[3], kernel_size=kernel_size[3])\n","    shortcut = batch_norm(shortcut, training)\n","  \n","  input = conv2d_fixed_padding(\n","      inputs=input, filters=filters[0], strides=strides[0], kernel_size=kernel_size[0])\n","  input = batch_norm(input, training)\n","  input = conv2d_fixed_padding(\n","      inputs=input, filters=filters[1], strides=strides[1], kernel_size=kernel_size[1])\n","  input = batch_norm(input, training)\n","  input = conv2d_fixed_padding(\n","      inputs=input, filters=filters[2], strides=strides[2], kernel_size=kernel_size[2])\n","  input = batch_norm(input, training)\n","  \n","  return tf.nn.relu(input + shortcut)\n","  \n","\n","def resnet50(features, labels, mode):\n","  training = (mode == tf.estimator.ModeKeys.TRAIN)\n","\n","  # Input Layer\n","  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n","  #input_layer = tf.reshape(features[\"x\"], [-1, 224, 224, 3])\n","  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n","\n","\n","  # Convolutional Layer #1\n","  conv1 = conv2d_fixed_padding(\n","      inputs=input_layer, filters=64, strides=2, kernel_size=7)\n","  conv1_norm = batch_norm(conv1, training)\n","  conv1_relu = tf.nn.relu(conv1_norm)\n","  pool1 = tf.layers.max_pooling2d(\n","    inputs=conv1_relu, pool_size=3, strides=2, padding='SAME',\n","    data_format='channels_last')\n","  \n","  kernel_size = [1, 3, 1, 1]\n","  filters_2 = [64, 64, 256, 256]\n","  strides_2 = [1, 1, 1, 1]\n","  \n","  #res2a\n","  res2a_relu = resnetUnit(pool1, filters_2, kernel_size, strides_2,\n","                          bottleneck = True, training = training)\n","  res2b_relu = resnetUnit(res2a_relu, filters_2, kernel_size, strides_2,\n","                          bottleneck = False, training = training)\n","  res2c_relu = resnetUnit(res2b_relu, filters_2, kernel_size, strides_2,\n","                          bottleneck = False, training = training)\n","  \n","  filters_3 = [128, 128, 512, 512]\n","  strides_3 = [2, 1, 1, 2]\n","  res3a_relu = resnetUnit(res2c_relu, filters_3, kernel_size, strides_3,\n","                          bottleneck = True, training = training)\n","  res3b_relu = resnetUnit(res3a_relu, filters_3, kernel_size, strides_2,\n","                          bottleneck = False, training = training)\n","  res3c_relu = resnetUnit(res3b_relu, filters_3, kernel_size, strides_2,\n","                          bottleneck = False, training = training)\n","  res3d_relu = resnetUnit(res3c_relu, filters_3, kernel_size, strides_2,\n","                          bottleneck = False, training = training)\n","  \n","  filters_4 = [256, 256, 1024, 1024]\n","  res4a_relu = resnetUnit(res3d_relu, filters_4, kernel_size, strides_3,\n","                          bottleneck = True, training = training)\n","  res4b_relu = resnetUnit(res4a_relu, filters_4, kernel_size, strides_2,\n","                          bottleneck = False, training = training)  \n","  res4c_relu = resnetUnit(res4b_relu, filters_4, kernel_size, strides_2,\n","                          bottleneck = False, training = training)  \n","  res4d_relu = resnetUnit(res4c_relu, filters_4, kernel_size, strides_2,\n","                          bottleneck = False, training = training)  \n","  res4e_relu = resnetUnit(res4d_relu, filters_4, kernel_size, strides_2,\n","                          bottleneck = False, training = training)  \n","  res4f_relu = resnetUnit(res4e_relu, filters_4, kernel_size, strides_2,\n","                          bottleneck = False, training = training) \n","  \n","  filters_5 = [512, 512, 2048, 2048]\n","  res5a_relu = resnetUnit(res4f_relu, filters_5, kernel_size, strides_3,\n","                          bottleneck = True, training = training)\n","  res5b_relu = resnetUnit(res5a_relu, filters_5, kernel_size, strides_2,\n","                          bottleneck = False, training = training) \n","  res5c_relu = resnetUnit(res5b_relu, filters_5, kernel_size, strides_2,\n","                          bottleneck = False, training = training) \n","\n","  # ResNet does an Average Pooling layer over pool_size.\n","  # Do a reduce_mean because it performs better than AveragePooling2D.\n","  axes = [1, 2]\n","  inputs = tf.reduce_mean(res5c_relu, axes, keepdims=True)\n","  inputs = tf.reshape(inputs, [-1, 1*1*2048])\n","  \n","  dense = tf.layers.dense(inputs=inputs, units=1000, activation=tf.nn.relu)\n","  dropout = tf.layers.dropout(inputs=dense, rate=0.5, training=training)\n","\n","  logits = tf.layers.dense(inputs=dropout, units=10)\n","\n","  predictions = {\n","      # Generate predictions (for PREDICT and EVAL mode)\n","      \"classes\": tf.argmax(input=logits, axis=1),\n","      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n","      # `logging_hook`.\n","      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n","  }\n","  if mode == tf.estimator.ModeKeys.PREDICT:\n","    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n","\n","  # Calculate Loss (for both TRAIN and EVAL modes)\n","  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n","\n","  accuracy = tf.metrics.accuracy(\n","          labels=labels, predictions=predictions[\"classes\"])\n","  \n","  # Configure the Training Op (for TRAIN mode)\n","  if mode == tf.estimator.ModeKeys.TRAIN:\n","    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n","    train_op = optimizer.minimize(\n","        loss=loss,\n","        global_step=tf.train.get_global_step())\n","    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n","  \n","\n","  # Add evaluation metrics (for EVAL mode)\n","  eval_metric_ops = { \"accuracy\": accuracy }\n","  return tf.estimator.EstimatorSpec(\n","      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n","\n","\n","def main(unused_argv):\n","  # Load training and eval data\n","  mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n","  train_data = mnist.train.images  # Returns np.array\n","  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n","  eval_data = mnist.test.images  # Returns np.array\n","  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n","\n","  # Create the Estimator\n","  mnist_classifier = tf.estimator.Estimator(\n","      model_fn=resnet50, model_dir=\"/model/test1\")\n","\n","  # Set up logging for predictions\n","  # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n","  tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n","  logging_hook = tf.train.LoggingTensorHook(\n","      tensors=tensors_to_log, every_n_iter=1000)\n","\n","  pred_input_fn = tf.estimator.inputs.numpy_input_fn(\n","      x={\"x\": train_data},\n","      shuffle=False)\n","  predict_results = mnist_classifier.predict(input_fn=pred_input_fn)\n","  print(len(list(predict_results)))\n","  file = open(\"prediction.txt\",\"w\") \n","  for i in predict_results:\n","    print(str(i['classes']))\n","    file.write(str(i['classes']))\n","  file.close()\n","  \n","\"\"\"\n","# Train the model\n","train_input_fn = tf.estimator.inputs.numpy_input_fn(\n","    x={\"x\": train_data},\n","    y=train_labels,\n","    batch_size=100,\n","    num_epochs=None,\n","    shuffle=True)\n","mnist_classifier.train(\n","    input_fn=train_input_fn,\n","    steps=100,\n","    hooks=[logging_hook])\n","\"\"\"\n","\"\"\"\n","# Evaluate the model and print results\n","eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n","    x={\"x\": eval_data},\n","    y=eval_labels,\n","    num_epochs=1,\n","    shuffle=False)\n","eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n","print(eval_results)\n","\"\"\"\n","  \n","if __name__ == \"__main__\":\n","  tf.app.run()\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Extracting MNIST-data/train-images-idx3-ubyte.gz\n","Extracting MNIST-data/train-labels-idx1-ubyte.gz\n","Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n","Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n","INFO:tensorflow:Using default config.\n","INFO:tensorflow:Using config: {'_model_dir': '/model/test1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f709a440d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["Exception ignored in: <generator object Estimator.predict at 0x7f70c69fbd00>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py\", line 519, in predict\n","    for key, value in six.iteritems(preds_evaluated)\n","  File \"/usr/lib/python3.6/contextlib.py\", line 99, in __exit__\n","    self.gen.throw(type, value, traceback)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 5265, in get_controller\n","    yield g\n","  File \"/usr/lib/python3.6/contextlib.py\", line 99, in __exit__\n","    self.gen.throw(type, value, traceback)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 5068, in get_controller\n","    type(default))\n","AssertionError: Nesting violated for default stack of <class 'tensorflow.python.framework.ops.Graph'> objects\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from /model/test1/model.ckpt-800\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","55000\n"],"name":"stdout"},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\n"]},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"],"name":"stderr"}]}]}